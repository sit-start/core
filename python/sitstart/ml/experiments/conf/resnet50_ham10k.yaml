# 75.3 val rec: https://wandb.ai/kevdale/resnet50_ham10k/runs/05075_00021
defaults:
  - _defaults_
  - trial/data: ham10k
  - trial/model: resnet50
  - _self_
eval:
  test:
    metrics:
      rec:
        _target_: sitstart.ml.metrics.AverageMulticlassRecall
        num_classes: ${trial.data.num_classes}
      conf:
        _target_: sitstart.ml.metrics.MulticlassConfusionMatrix
        num_classes: ${trial.data.num_classes}
        labels: ${trial.data.class_labels}
        normalize: "true"
  train:
    metrics: null
  select:
    metric: val_rec
    mode: max
max_num_epochs: 50
name: resnet50_ham10k
param_space:
  train_loop_config:
    lr: ${rt.grid_search:[1e-3]}
    batch_size: ${rt.grid_search:[48]}
    dropout: ${rt.grid_search:[0]}
    fc_dropout: ${rt.grid_search:[0]}
    gamma: ${rt.grid_search:[2.5]}
    criteria_gamma: ${rt.grid_search:[0.5]}
    rebalance_gamma: ${rt.grid_search:[0]}
    weight_decay: ${rt.grid_search:[1e-4]}
trial:
  data:
    batch_size: ${param_space.train_loop_config.batch_size}
    module:
      augment: ${trial.data.augment.transform}
      collate:
        _target_: sitstart.ml.transforms.CutMixUpCollateTransform
        num_classes: ${trial.data.num_classes}
      criteria_gamma: ${param_space.train_loop_config.criteria_gamma}
      dedupe: true
      rebalance_gamma: ${param_space.train_loop_config.rebalance_gamma}
  loss_fn:
    _target_: sitstart.ml.losses.FocalLoss
    gamma: ${param_space.train_loop_config.gamma}
  model:
    target_size: { crop: 443, resize: 450 }
    module:
      append:
        layer*.*.relu:
          _target_: torch.nn.Dropout2d
          p: ${param_space.train_loop_config.dropout}
        avgpool:
          _target_: torch.nn.Dropout2d
          p: ${param_space.train_loop_config.fc_dropout}
    transforms:
      image_classification:
        std: ${trial.data.std}
        mean: ${trial.data.mean}
  optimizer:
    _partial_: true
    _target_: torch.optim.AdamW
    lr: ${param_space.train_loop_config.lr}
    weight_decay: ${param_space.train_loop_config.weight_decay}
tune:
  num_samples: 1
  search_alg: random
  scheduler:
    grace_period: ${max_num_epochs}
